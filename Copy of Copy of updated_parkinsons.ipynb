{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"5EJjbAkEStUP","outputId":"3b1c0c08-d1db-4a58-9eb7-2e58bac61abd"},"outputs":[{"name":"stdout","output_type":"stream","text":["             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n","0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n","1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n","2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n","3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n","4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n","\n","   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n","0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n","1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n","2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n","3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n","4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n","\n","   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n","0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n","1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n","2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n","3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n","4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n","\n","    spread2        D2       PPE  \n","0  0.266482  2.301442  0.284654  \n","1  0.335590  2.486855  0.368674  \n","2  0.311173  2.342259  0.332634  \n","3  0.334147  2.405554  0.368975  \n","4  0.234513  2.332180  0.410335  \n","\n","[5 rows x 24 columns]\n","Epoch 0: Loss: 0.2500\n","Epoch 100: Loss: 0.1668\n","Epoch 200: Loss: 0.1445\n","Epoch 300: Loss: 0.1316\n","Epoch 400: Loss: 0.1233\n","Epoch 500: Loss: 0.1176\n","Epoch 600: Loss: 0.1135\n","Epoch 700: Loss: 0.1103\n","Epoch 800: Loss: 0.1079\n","Epoch 900: Loss: 0.1059\n","Epoch 1000: Loss: 0.1043\n","Epoch 1100: Loss: 0.1029\n","Epoch 1200: Loss: 0.1018\n","Epoch 1300: Loss: 0.1008\n","Epoch 1400: Loss: 0.1000\n","Epoch 1500: Loss: 0.0992\n","Epoch 1600: Loss: 0.0986\n","Epoch 1700: Loss: 0.0980\n","Epoch 1800: Loss: 0.0975\n","Epoch 1900: Loss: 0.0970\n","Epoch 2000: Loss: 0.0966\n","Epoch 2100: Loss: 0.0962\n","Epoch 2200: Loss: 0.0958\n","Epoch 2300: Loss: 0.0955\n","Epoch 2400: Loss: 0.0952\n","Epoch 2500: Loss: 0.0950\n","Epoch 2600: Loss: 0.0947\n","Epoch 2700: Loss: 0.0945\n","Epoch 2800: Loss: 0.0943\n","Epoch 2900: Loss: 0.0941\n","Epoch 3000: Loss: 0.0939\n","Epoch 3100: Loss: 0.0937\n","Epoch 3200: Loss: 0.0936\n","Epoch 3300: Loss: 0.0934\n","Epoch 3400: Loss: 0.0933\n","Epoch 3500: Loss: 0.0931\n","Epoch 3600: Loss: 0.0930\n","Epoch 3700: Loss: 0.0929\n","Epoch 3800: Loss: 0.0928\n","Epoch 3900: Loss: 0.0926\n","Epoch 4000: Loss: 0.0925\n","Epoch 4100: Loss: 0.0924\n","Epoch 4200: Loss: 0.0923\n","Epoch 4300: Loss: 0.0923\n","Epoch 4400: Loss: 0.0922\n","Epoch 4500: Loss: 0.0921\n","Epoch 4600: Loss: 0.0920\n","Epoch 4700: Loss: 0.0919\n","Epoch 4800: Loss: 0.0918\n","Epoch 4900: Loss: 0.0918\n","Test Accuracy: 0.7500\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# Load the data from the CSV file into a Pandas DataFrame\n","parkinsons_data = pd.read_csv(\"/content/parkinsons.csv\")\n","print(parkinsons_data.head())\n","\n","# Splitting features and target\n","X = parkinsons_data.drop(columns=['name', 'status'], axis=1).values\n","Y = parkinsons_data['status'].values\n","\n","# Split the dataset into training and testing sets\n","X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X, Y, test_size=0.1, random_state=2)\n","\n","# Scale the data\n","scaler1 = StandardScaler()\n","X_train1 = scaler1.fit_transform(X_train1)\n","X_test1 = scaler1.transform(X_test1)\n","\n","# Parameters for gradient descent\n","epochs = 5000\n","learning_rate = 0.01\n","m, n = X_train1.shape\n","\n","# Initialize weights and bias\n","weights = np.zeros(n)\n","bias = 0\n","\n","# Function to calculate loss\n","def compute_loss(y_true, y_pred):\n","    return np.mean((y_true - y_pred) ** 2)\n","\n","# Training the model using gradient descent\n","for epoch in range(epochs):\n","    linear_model = np.dot(X_train1, weights) + bias\n","    y_pred = 1 / (1 + np.exp(-linear_model))  # Sigmoid activation\n","\n","    # Gradient calculation\n","    dw = (1/m) * np.dot(X_train1.T, (y_pred - Y_train1))\n","    db = (1/m) * np.sum(y_pred - Y_train1)\n","\n","    # Update weights and bias\n","    weights -= learning_rate * dw\n","    bias -= learning_rate * db\n","\n","    # Compute and print loss every 100 epochs\n","    if epoch % 100 == 0:\n","        loss = compute_loss(Y_train1, y_pred)\n","        print(f\"Epoch {epoch}: Loss: {loss:.4f}\")\n","\n","# Final evaluation on test set\n","final_predictions = 1 / (1 + np.exp(-(np.dot(X_test1, weights) + bias)))\n","final_predictions = (final_predictions > 0.5).astype(int)  # Convert probabilities to binary predictions\n","\n","# Calculate accuracy\n","accuracy = np.mean(final_predictions == Y_test1)\n","print(f\"Test Accuracy: {accuracy:.4f}\")\n","\n","# Input for predictions\n","x = int(input(\"Enter how many times you want to predict the answer: \"))\n","while x > 0:\n","    input_data = []\n","\n","    for i in range(X.shape[1]):\n","        while True:\n","            try:\n","                y = float(input(f\"Enter value for feature {i + 1}: \"))\n","                input_data.append(y)\n","                break\n","            except ValueError:\n","                print(\"Invalid input. Please enter a numeric value.\")\n","\n","    input_data_as_numpy_array = np.asarray(input_data)\n","    input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)\n","\n","    # Scale the input data\n","    std_data = scaler1.transform(input_data_reshaped)\n","\n","    # Make prediction\n","    prediction = 1 / (1 + np.exp(-(np.dot(std_data, weights) + bias)))\n","\n","    if prediction[0] < 0.5:\n","        print(\"The person does not have Parkinson's disease.\")\n","    else:\n","        print(\"The person has Parkinson's disease.\")\n","\n","    x -= 1  # Decrease the count for predictions"]},{"cell_type":"code","source":[],"metadata":{"id":"2VOwG9f6bwjg"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1WhuZKzdsdf5udARCkH1ro8oQzET-eFR_","timestamp":1729570483640}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}